{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJI45mrnfHg0TWRMndd2Uf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AaryanAnand10/Implant/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp9zgjn4n0ZL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "import time\n",
        "import copy\n",
        "\n",
        "# Check for GPU availability and set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Path to the knee implant folder\n",
        "# Ensure your Google Drive is mounted if using Colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "base_path = \"/content/drive/MyDrive/Knee\" # Adjust if your path is different\n",
        "\n",
        "# Basic parameters\n",
        "img_size = 224 # Standard size for many CNNs\n",
        "batch_size = 32 # Adjust based on GPU memory\n",
        "learning_rate = 0.001\n",
        "num_epochs = 30 # Start with a moderate number, can increase if needed\n",
        "patience = 7 # For early stopping\n",
        "\n",
        "print(\"Step 1: Setup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for training and validation sets\n",
        "# Use standard ImageNet normalization stats as a starting point\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# Augmentation for training data\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.RandomRotation(10), # Limited rotation for medical images\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1), # Slight color adjustments\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "# Minimal transformation for validation data\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "# Load the dataset using ImageFolder\n",
        "try:\n",
        "    full_dataset = datasets.ImageFolder(base_path)\n",
        "    class_names = full_dataset.classes\n",
        "    num_classes = len(class_names)\n",
        "    print(f\"Found {len(full_dataset)} images in {num_classes} classes:\")\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        print(f\"- {class_name} (Index: {i})\")\n",
        "\n",
        "    # Split dataset into training and validation sets (80/20 split)\n",
        "    val_split = 0.2\n",
        "    val_size = int(val_split * len(full_dataset))\n",
        "    train_size = len(full_dataset) - val_size\n",
        "\n",
        "    # Ensure reproducibility\n",
        "    generator = torch.Generator().manual_seed(42)\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=generator)\n",
        "\n",
        "    # Apply respective transformations\n",
        "    train_dataset.dataset.transform = train_transform\n",
        "    # We need to wrap the validation subset to apply the transform correctly\n",
        "    # Create a new Subset with the correct transform\n",
        "    val_indices = val_dataset.indices\n",
        "    val_dataset_transformed = Subset(datasets.ImageFolder(base_path, transform=val_transform), val_indices)\n",
        "\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset_transformed, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    dataloaders = {'train': train_loader, 'val': val_loader}\n",
        "    dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset_transformed)}\n",
        "\n",
        "    print(f\"Training samples: {dataset_sizes['train']}, Validation samples: {dataset_sizes['val']}\")\n",
        "    print(\"Step 2: Data loading and preprocessing complete\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Dataset path not found at {base_path}. Please check the path.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during data loading: {e}\")\n"
      ],
      "metadata": {
        "id": "y4zI_FaLn-Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN architecture\n",
        "class KneeImplantCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(KneeImplantCNN, self).__init__()\n",
        "        # Convolutional Block 1\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32) # BN after Conv, before ReLU [[8]]\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # Output: 112x112\n",
        "\n",
        "        # Convolutional Block 2\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # Output: 56x56\n",
        "\n",
        "        # Convolutional Block 3\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # Output: 28x28\n",
        "\n",
        "        # Convolutional Block 4 (Optional, keep model smaller)\n",
        "        # self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        # self.bn4 = nn.BatchNorm2d(256)\n",
        "        # self.relu4 = nn.ReLU()\n",
        "        # self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # Output: 14x14\n",
        "\n",
        "        # Flatten layer\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        # Calculate the flattened size dynamically (assuming Block 3 is last)\n",
        "        # Size = 128 filters * 28 * 28 feature map size\n",
        "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
        "        self.bn_fc1 = nn.BatchNorm1d(512) # BN for dense layer\n",
        "        self.relu_fc1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.5) # Dropout for regularization\n",
        "\n",
        "        self.fc2 = nn.Linear(512, num_classes) # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(self.relu3(self.bn3(self.conv3(x))))\n",
        "        # if using Block 4: x = self.pool4(self.relu4(self.bn4(self.conv4(x))))\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout1(self.relu_fc1(self.bn_fc1(self.fc1(x))))\n",
        "        x = self.fc2(x) # Raw logits output\n",
        "        return x\n",
        "\n",
        "# Instantiate the model and move it to the device\n",
        "model = KneeImplantCNN(num_classes).to(device)\n",
        "print(model)\n",
        "print(\"Step 3: CNN model defined\")"
      ],
      "metadata": {
        "id": "_j1GQZjMn-OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function - CrossEntropyLoss includes Softmax\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer - Adam is a good default\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Learning Rate Scheduler - Reduce LR on plateau\n",
        "# Monitors validation loss and reduces LR if it stops improving\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "print(\"Step 4: Loss, optimizer, and scheduler defined\")"
      ],
      "metadata": {
        "id": "Ie-njYkPn-Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, patience=7):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    epochs_no_improve = 0 # Counter for early stopping\n",
        "\n",
        "    # Store history\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                # Track history only in train phase\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward pass + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # Store history\n",
        "            if phase == 'train':\n",
        "                history['train_loss'].append(epoch_loss)\n",
        "                history['train_acc'].append(epoch_acc.item()) # Use .item() to get Python number\n",
        "            else:\n",
        "                history['val_loss'].append(epoch_loss)\n",
        "                history['val_acc'].append(epoch_acc.item())\n",
        "\n",
        "                # Adjust learning rate based on validation loss\n",
        "                scheduler.step(epoch_loss)\n",
        "\n",
        "                # Check for improvement for early stopping and best model saving\n",
        "                if epoch_acc > best_acc:\n",
        "                    print(f\"Validation accuracy improved ({best_acc:.4f} --> {epoch_acc:.4f}). Saving model...\")\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    epochs_no_improve = 0\n",
        "                    # Save the best model weights\n",
        "                    torch.save(model.state_dict(), 'knee_implant_cnn_best.pth')\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "                    print(f\"Validation accuracy did not improve for {epochs_no_improve} epochs.\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "            break\n",
        "        print()\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:.4f}')\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n",
        "\n",
        "# Start training\n",
        "print(\"Step 5: Starting model training...\")\n",
        "model, history = train_model(model, criterion, optimizer, scheduler, num_epochs=num_epochs, patience=patience)\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "pqspOrJCn-bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "def plot_history(history):\n",
        "    # Convert tensor accuracies to float if needed\n",
        "    train_acc = [acc for acc in history['train_acc']]\n",
        "    val_acc = [acc for acc in history['val_acc']]\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_acc, label='Train Accuracy')\n",
        "    plt.plot(val_acc, label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('pytorch_training_history.png')\n",
        "    plt.show()\n",
        "\n",
        "print(\"Step 6: Plotting training history...\")\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "32kFilU7oHIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient calculations\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    accuracy = np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
        "    print(f\"\\nOverall Validation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names, zero_division=0))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(15, 12))\n",
        "\n",
        "    # Use shorter names for readability\n",
        "    short_names = [name[:12] + '...' if len(name) > 12 else name for name in class_names]\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=short_names, yticklabels=short_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('pytorch_confusion_matrix.png')\n",
        "    plt.show()\n",
        "\n",
        "print(\"Step 7: Evaluating the best model...\")\n",
        "# Load the best model weights before evaluation\n",
        "model.load_state_dict(torch.load('knee_implant_cnn_best.pth'))\n",
        "evaluate_model(model, val_loader)"
      ],
      "metadata": {
        "id": "Pti0OMH_oHKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction function\n",
        "def predict_implant(image_path, model, class_names, transform):\n",
        "    model.eval() # Set model to evaluation mode\n",
        "    try:\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Image file not found at {image_path}\")\n",
        "        return None\n",
        "\n",
        "    # Apply the *validation* transform\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img_tensor)\n",
        "        probabilities = torch.softmax(outputs, dim=1)[0]\n",
        "        top_p, top_class_idx = probabilities.topk(3, dim=0)\n",
        "\n",
        "    top_predictions = []\n",
        "    for i in range(top_p.size(0)):\n",
        "        idx = top_class_idx[i].item()\n",
        "        prob = top_p[i].item() * 100\n",
        "        class_name = class_names[idx]\n",
        "        top_predictions.append((class_name, prob))\n",
        "\n",
        "    # Display results\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted: {top_predictions[0][0]}\\nConfidence: {top_predictions[0][1]:.1f}%\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Show other predictions as text\n",
        "    result_text = \"\\n\".join([f\"{i+1}. {name}: {conf:.1f}%\" for i, (name, conf) in enumerate(top_predictions)])\n",
        "    plt.figtext(0.5, 0.01, result_text, ha='center', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return top_predictions\n",
        "\n",
        "print(\"Step 8: Prediction function ready.\")\n",
        "# Example usage:\n",
        "# Load the best model first\n",
        "# model.load_state_dict(torch.load('knee_implant_cnn_best.pth'))\n",
        "# predict_implant('/content/drive/MyDrive/Knee/Depuy AMK/example.jpg', model, class_names, val_transform)"
      ],
      "metadata": {
        "id": "0VFN1B0AoHNq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}